{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spark ql Queries part 2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#CS 5540 Project Phase 2 - Design and implement your ideas using Apache Spark\n",
        "##Install Spark (Steps explained in detail in other notebook - Aparche_Ye.ipynb)"
      ],
      "metadata": {
        "id": "9jwfjaFerMpB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "metadata": {
        "id": "e6OEZoq16u82"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hhSeSYf457v8"
      },
      "outputs": [],
      "source": [
        "!wget -q https://archive.apache.org/dist/spark/spark-3.3.0/spark-3.3.0-bin-hadoop3.tgz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar xf spark-3.3.0-bin-hadoop3.tgz"
      ],
      "metadata": {
        "id": "ltilEHZs61ph"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "Mz5mPvgc63vb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.0-bin-hadoop3\""
      ],
      "metadata": {
        "id": "elHfbNZh67AQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "\n",
        "findspark.init()\n",
        "findspark.find()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JdZoyrkv7C3a",
        "outputId": "c2188ea3-3cbf-459a-add5-db1b2871f06f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/spark-3.3.0-bin-hadoop3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.conf import SparkConf\n",
        "from pyspark.context import SparkContext\n",
        "conf = SparkConf().setAppName(\"SparkWordCount\").setMaster('local')\n",
        "import findspark\n",
        "sc = SparkContext(conf=conf)"
      ],
      "metadata": {
        "id": "qw9WzooF7pmw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyarrow==8.0."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a52NZx1F7tU8",
        "outputId": "300692a9-7778-4b64-ed9e-c50dffbc49cb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyarrow==8.0.\n",
            "  Downloading pyarrow-8.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.3 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29.3 MB 55.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from pyarrow==8.0.) (1.21.6)\n",
            "Installing collected packages: pyarrow\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 6.0.1\n",
            "    Uninstalling pyarrow-6.0.1:\n",
            "      Successfully uninstalled pyarrow-6.0.1\n",
            "Successfully installed pyarrow-8.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SQLContext\n",
        "import pyarrow\n",
        "\n",
        "conf = SparkConf().set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\").setMaster('local')\n",
        "sqlContext = SQLContext(sc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSFx9-lCrySH",
        "outputId": "f8644367-af14-41c5-8014-ba6171a3e601"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/spark-3.3.0-bin-hadoop3/python/pyspark/sql/context.py:114: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##After the successful installation of Spark, read the csv file containing tweets\n",
        "\n",
        "###Loading data into PySpark"
      ],
      "metadata": {
        "id": "4sVKNITorjd4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#store the tweets in spark df\n",
        "df = sqlContext.read.csv(\"tweets_10k.csv\", header='True', sep=',',inferSchema=False, multiLine=True)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVw5Jo4Hr-fW",
        "outputId": "d5ddbaa8-f30c-4e4f-89a1-545861372935"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+\n",
            "|_c0|               tweet|          created_at|            hashtags|                urls|             source|                user|\n",
            "+---+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+\n",
            "|  0|RT @JoeBiden: The...|2022-07-15 20:42:...|                  []|                  []|   Twitter for iPad|User(_api=<tweepy...|\n",
            "|  1|@Jacob_Rees_Mogg ...|2022-07-15 20:42:...|                  []|                  []|    Twitter Web App|User(_api=<tweepy...|\n",
            "|  2|RT @Sbh08Mae: @Re...|2022-07-15 20:42:...|[{'text': 'WA08',...|                  []|    Twitter Web App|User(_api=<tweepy...|\n",
            "|  3|RT @JoeBiden: The...|2022-07-15 20:42:...|                  []|                  []|   Twitter for iPad|User(_api=<tweepy...|\n",
            "|  4|@RussianEmbassy @...|2022-07-15 20:42:...|                  []|                  []|    Twitter Web App|User(_api=<tweepy...|\n",
            "|  5|RT @taykuy: That ...|2022-07-15 20:42:...|                  []|                  []| Twitter for iPhone|User(_api=<tweepy...|\n",
            "|  6|RT @JoeBiden: The...|2022-07-15 20:42:...|                  []|                  []|Twitter for Android|User(_api=<tweepy...|\n",
            "|  7|The price of oil ...|2022-07-15 20:42:...|                  []|                  []|             Buffer|User(_api=<tweepy...|\n",
            "|  8|RT @CLBunny1225: ...|2022-07-15 20:42:...|[{'text': 'NFTs',...|[{'url': 'https:/...| Twitter for iPhone|User(_api=<tweepy...|\n",
            "|  9|RT @brainclubnft:...|2022-07-15 20:41:...|                  []|[{'url': 'https:/...| Twitter for iPhone|User(_api=<tweepy...|\n",
            "| 10|RT @JoeBiden: The...|2022-07-15 20:41:...|                  []|                  []|Twitter for Android|User(_api=<tweepy...|\n",
            "| 11|RT @bint72: To so...|2022-07-15 20:41:...|                  []|                  []|Twitter for Android|User(_api=<tweepy...|\n",
            "| 12|RT @WHCOS: Today ...|2022-07-15 20:41:...|                  []|[{'url': 'https:/...|    Twitter Web App|User(_api=<tweepy...|\n",
            "| 13|RT @ActionDemocra...|2022-07-15 20:41:...|                  []|                  []| Twitter for iPhone|User(_api=<tweepy...|\n",
            "| 14|@zerohedge You ta...|2022-07-15 20:41:...|                  []|                  []|Twitter for Android|User(_api=<tweepy...|\n",
            "| 15|RT @JoeBiden: The...|2022-07-15 20:41:...|                  []|                  []|    Twitter Web App|User(_api=<tweepy...|\n",
            "| 16|RT @JoeBiden: The...|2022-07-15 20:41:...|                  []|                  []|    Twitter Web App|User(_api=<tweepy...|\n",
            "| 17|@unusual_whales I...|2022-07-15 20:41:...|                  []|                  []| Twitter for iPhone|User(_api=<tweepy...|\n",
            "| 18|RT @JoeBiden: The...|2022-07-15 20:41:...|                  []|                  []| Twitter for iPhone|User(_api=<tweepy...|\n",
            "| 19|RT @AngliaTools: ...|2022-07-15 20:41:...|                  []|[{'url': 'https:/...| Twitter for iPhone|User(_api=<tweepy...|\n",
            "+---+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#schema of the datafarame\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYln-mPY9PTf",
        "outputId": "fa54e9b5-6106-4521-c4b6-cfca0f9bc0b8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- _c0: string (nullable = true)\n",
            " |-- tweet: string (nullable = true)\n",
            " |-- created_at: string (nullable = true)\n",
            " |-- hashtags: string (nullable = true)\n",
            " |-- urls: string (nullable = true)\n",
            " |-- source: string (nullable = true)\n",
            " |-- user: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Analytic Queries:\n",
        "\n",
        "##Query 1: Get the number tweets tweeeted every minute from the collected data\n",
        "\n",
        "Step 1: Extract the 'created_at' column taht containe time stamp."
      ],
      "metadata": {
        "id": "G-IiY09DsOf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#extract created_at column to a new dates spark datafarame\n",
        "dates = df.select(\"created_at\")\n",
        "dates.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40fgU3gGsR_-",
        "outputId": "ba9c943f-0732-4d39-982a-1a1d5df13952"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|          created_at|\n",
            "+--------------------+\n",
            "|2022-07-15 20:42:...|\n",
            "|2022-07-15 20:42:...|\n",
            "|2022-07-15 20:42:...|\n",
            "|2022-07-15 20:42:...|\n",
            "|2022-07-15 20:42:...|\n",
            "|2022-07-15 20:42:...|\n",
            "|2022-07-15 20:42:...|\n",
            "|2022-07-15 20:42:...|\n",
            "|2022-07-15 20:42:...|\n",
            "|2022-07-15 20:41:...|\n",
            "|2022-07-15 20:41:...|\n",
            "|2022-07-15 20:41:...|\n",
            "|2022-07-15 20:41:...|\n",
            "|2022-07-15 20:41:...|\n",
            "|2022-07-15 20:41:...|\n",
            "|2022-07-15 20:41:...|\n",
            "|2022-07-15 20:41:...|\n",
            "|2022-07-15 20:41:...|\n",
            "|2022-07-15 20:41:...|\n",
            "|2022-07-15 20:41:...|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Format the 'created_at' column to get only hour and minute part of the time stamp"
      ],
      "metadata": {
        "id": "1kBH84dbumKu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import date_format\n",
        "\n",
        "#use spark ql function date_format to extract the time part from the timestamp\n",
        "q = df.withColumn('created_at', date_format('created_at', 'HH:mm'))\n",
        "dates = q.select(\"created_at\")\n",
        "dates.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCCn0fGDvICF",
        "outputId": "b8da0448-b985-4795-8562-cbe1dc4859b4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+\n",
            "|created_at|\n",
            "+----------+\n",
            "|     20:42|\n",
            "|     20:42|\n",
            "|     20:42|\n",
            "|     20:42|\n",
            "|     20:42|\n",
            "|     20:42|\n",
            "|     20:42|\n",
            "|     20:42|\n",
            "|     20:42|\n",
            "|     20:41|\n",
            "|     20:41|\n",
            "|     20:41|\n",
            "|     20:41|\n",
            "|     20:41|\n",
            "|     20:41|\n",
            "|     20:41|\n",
            "|     20:41|\n",
            "|     20:41|\n",
            "|     20:41|\n",
            "|     20:41|\n",
            "+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Find the count of tweets tweeted every minute "
      ],
      "metadata": {
        "id": "ha4vO3eQu1LF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import countDistinct\n",
        "\n",
        "#drop all the null values\n",
        "dates = dates.na.drop()\n",
        "\n",
        "#get the count of tweets at every minute\n",
        "distinct_count = dates.groupBy(\"created_at\").count()\n",
        "distinct_count.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYmz31pp30CM",
        "outputId": "9059ec33-5ffc-4185-cd33-3b7656d4fed9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+\n",
            "|created_at|count|\n",
            "+----------+-----+\n",
            "|     18:47|   20|\n",
            "|     17:58|   21|\n",
            "|     19:03|   28|\n",
            "|     18:05|   11|\n",
            "|     17:35|   36|\n",
            "|     17:23|   35|\n",
            "|     16:29|   10|\n",
            "|     12:41|   14|\n",
            "|     12:26|   26|\n",
            "|     13:56|   10|\n",
            "|     13:49|   14|\n",
            "|     13:13|    6|\n",
            "|     18:12|   19|\n",
            "|     18:09|   27|\n",
            "|     17:14|    9|\n",
            "|     16:13|   12|\n",
            "|     19:19|   16|\n",
            "|     18:32|   19|\n",
            "|     18:13|   19|\n",
            "|     14:47|   10|\n",
            "+----------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Query 2: Get the time at which maximum number of tweets were tweeted/retweeted or the most popular time.\n",
        "\n",
        "The tweets were collected on July 15th 2022. The most popular time looks to be 17:17 or 5:17PM where in that one minute 88 tweets were collected."
      ],
      "metadata": {
        "id": "LjS63puARsOT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dates.groupBy(\"created_at\").count().orderBy(\"count\", ascending=False).show(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATw0-bwAV_sd",
        "outputId": "ff236006-742a-4c44-d661-781ce47fcc44"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+\n",
            "|created_at|count|\n",
            "+----------+-----+\n",
            "|     17:17|   88|\n",
            "+----------+-----+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Query 3: Get the time at which minimum number of tweets were tweeted/retweeted or find the least popular time.\n",
        "\n",
        "The tweets were collected on July 15th 2022. The least popular time looks to be 12:13 PM where in that one minute only 1 tweet was collected."
      ],
      "metadata": {
        "id": "fExg4m8FXTkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dates.groupBy(\"created_at\").count().orderBy(\"count\", ascending=True).show(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVUnakGTXk-W",
        "outputId": "d0c9f812-eb43-492c-a08f-9316ed80bd0c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+\n",
            "|created_at|count|\n",
            "+----------+-----+\n",
            "|     12:13|    1|\n",
            "+----------+-----+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Query 4: Get the range of time the tweets were collected\n",
        "\n",
        "The tweets were collected from 12:02 to 20:42 (8:42PM)"
      ],
      "metadata": {
        "id": "g8TLRD_MX5FV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, max as max_, min as min_\n",
        "\n",
        "(dates.withColumn(\"created_at\", col(\"created_at\"))\n",
        "    .agg(min_(\"created_at\"))).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEnlcrVuaKsP",
        "outputId": "b8245f0d-f584-4d97-cd32-794f3fa57f67"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+\n",
            "|min(created_at)|\n",
            "+---------------+\n",
            "|          12:02|\n",
            "+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(dates.withColumn(\"created_at\", col(\"created_at\"))\n",
        "    .agg(max_(\"created_at\"))).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuCc7YUReJlU",
        "outputId": "4d6ffa04-0d4d-4805-a6ae-a4c5297b3148"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+\n",
            "|max(created_at)|\n",
            "+---------------+\n",
            "|          20:42|\n",
            "+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Query 5: Number of retweets to Joe Biden every hour\n",
        "\n",
        "As seen below, 17:00 to 18:00 or 5PM-6PM is the time frame when most people retweeted to 'Joe Biden'. It is also interesting to note that 5:17PM which is in the time frame 5-6PM was the minute with maximum tweets in our collected data.\n",
        "\n",
        "2-3PM is the time frame when there least number of retweets to Joe Biden."
      ],
      "metadata": {
        "id": "oJYfU-WRX6Tq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tweet_and_time = df.select(\"created_at\", \"tweet\")\n",
        "joe_data = tweet_and_time.filter(col(\"tweet\").startswith(\"RT @JoeBiden\"))\n",
        "joe_data=joe_data.withColumn('created_at', date_format('created_at', 'HH')).groupBy(\"created_at\").count().orderBy(\"count\", ascending=False).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JThYTUEfZGx",
        "outputId": "d908150f-6f01-4c19-fabf-bc3973764724"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+\n",
            "|created_at|count|\n",
            "+----------+-----+\n",
            "|        17| 1050|\n",
            "|        18|  503|\n",
            "|        19|  402|\n",
            "|        20|  274|\n",
            "+----------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Query 6: Sentiment analysis of tweets\n",
        "Polarity is float which lies in the range of [-1,1] where 1 means positive statement and -1 means a negative statement. Subjective sentences generally refer to personal opinion, emotion or judgment whereas objective refers to factual information. Subjectivity is also a float which lies in the range of [0,1]."
      ],
      "metadata": {
        "id": "5TA5j9MnnoNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql import functions as F\n",
        "from textblob import TextBlob\n",
        "\n",
        "def preprocessing(lines):\n",
        "    words = lines.select(explode(split(lines.tweet, \"t_end\")).alias(\"word\"))\n",
        "    words = words.na.replace('', None)\n",
        "    words = words.na.drop()\n",
        "    words = words.withColumn('word', F.regexp_replace('word', r'http\\S+', ''))\n",
        "    words = words.withColumn('word', F.regexp_replace('word', '@\\w+', ''))\n",
        "    words = words.withColumn('word', F.regexp_replace('word', '#', ''))\n",
        "    words = words.withColumn('word', F.regexp_replace('word', 'RT', ''))\n",
        "    words = words.withColumn('word', F.regexp_replace('word', ':', ''))\n",
        "    return words\n",
        "\n",
        "    # text classification\n",
        "def polarity_detection(text):\n",
        "    return TextBlob(text).sentiment.polarity\n",
        "def subjectivity_detection(text):\n",
        "    return TextBlob(text).sentiment.subjectivity\n",
        "def text_classification(words):\n",
        "    # polarity detection\n",
        "    polarity_detection_udf = udf(polarity_detection, StringType())\n",
        "    words = words.withColumn(\"polarity\", polarity_detection_udf(\"word\"))\n",
        "    # subjectivity detection\n",
        "    subjectivity_detection_udf = udf(subjectivity_detection, StringType())\n",
        "    words = words.withColumn(\"subjectivity\", subjectivity_detection_udf(\"word\"))\n",
        "    return words\n",
        "\n",
        "words = preprocessing(df.select('tweet'))\n",
        "    # text classification to define polarity and subjectivity\n",
        "words = text_classification(words)\n",
        "words = words.repartition(1)\n",
        "words.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qsjkbYIloaC",
        "outputId": "19d5add2-67b9-4e30-afde-5712c24eabc9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+-------------------+\n",
            "|                word|            polarity|       subjectivity|\n",
            "+--------------------+--------------------+-------------------+\n",
            "|  The price of oi...|-0.00444444444444...| 0.5311111111111111|\n",
            "| I believe the pr...|0.044387755102040814| 0.3086734693877551|\n",
            "|   knows gas &amp...|                 0.0|                0.0|\n",
            "|  The price of oi...|-0.00444444444444...| 0.5311111111111111|\n",
            "|           EU is ...|-0.13888888888888887| 0.2222222222222222|\n",
            "|  That is an 8.5%...|               -0.03|0.29666666666666663|\n",
            "|  The price of oi...|-0.00444444444444...| 0.5311111111111111|\n",
            "|The price of oil ...|-0.01203703703703...| 0.4509259259259259|\n",
            "|  Check our anime...|                 0.0|                0.0|\n",
            "|  ‚ö°Ô∏èBrain 207 LIS...|                 0.0|                0.0|\n",
            "|  The price of oi...|-0.00444444444444...| 0.5311111111111111|\n",
            "|  To solve all pr...|                 0.0|                0.0|\n",
            "|  Today is day 31...|                 0.0|                0.0|\n",
            "|  Sure Gas prices...| 0.43200000000000005| 0.6057777777777777|\n",
            "| You talking abou...|                 0.0|                0.0|\n",
            "|  The price of oi...|-0.00444444444444...| 0.5311111111111111|\n",
            "|  The price of oi...|-0.00444444444444...| 0.5311111111111111|\n",
            "| If Biden returns...|                 0.0|                0.0|\n",
            "|  The price of oi...|-0.00444444444444...| 0.5311111111111111|\n",
            "|  We have nailed ...|-0.15555555555555559| 0.2888888888888889|\n",
            "+--------------------+--------------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Let's consider tweets with polarity >=0.5 to be positive and tweets with polarity value <=-0.5 to be negative\n",
        "\n",
        "Positive tweets"
      ],
      "metadata": {
        "id": "hcnxxuIKosPX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words.select(\"word\").filter(col(\"polarity\") >= 0.5).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iaTxA4VnuIL",
        "outputId": "547a842e-30e9-42b3-df7b-c9f5b4e6f02c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|                word|\n",
            "+--------------------+\n",
            "| Republican strat...|\n",
            "| Gas price July 1...|\n",
            "|Welcome to the Wo...|\n",
            "| Oh no....if they...|\n",
            "|   I had a gas st...|\n",
            "|\"Biden \"\"We'll se...|\n",
            "|   If that NYC pu...|\n",
            "|\" If that NYC pub...|\n",
            "| He should sell l...|\n",
            "|  Sure, and Biden...|\n",
            "|US Presidents are...|\n",
            "|I don't see many ...|\n",
            "|Oh  , done good n...|\n",
            "| üòÇ sana si leni ...|\n",
            "|   The price of g...|\n",
            "|  ‚ùåExtracting mor...|\n",
            "| Just don't tell ...|\n",
            "|  Good to see gas...|\n",
            "|Rep. Emanuel Clea...|\n",
            "|  Good to see gas...|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Negative tweets"
      ],
      "metadata": {
        "id": "mIyIahV9pI6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words.select(\"word\").filter(col(\"polarity\") <= -0.5).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFxzQdWHpBm3",
        "outputId": "b4a55cc3-06ee-4756-e555-9de1b5b14e70"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|                word|\n",
            "+--------------------+\n",
            "| Election Day 202...|\n",
            "|  Gas buddy price...|\n",
            "| Was this played ...|\n",
            "|\"BIDENS WORRIED A...|\n",
            "|I will be holding...|\n",
            "| You made the inf...|\n",
            "|  We could have t...|\n",
            "| Price controls f...|\n",
            "|     And even tho...|\n",
            "| Unhappy with Bid...|\n",
            "|  While oil + gas...|\n",
            "| Videos policies ...|\n",
            "| THE BROWN STAIN ...|\n",
            "|  We could have t...|\n",
            "|\"\"\"It takes time ...|\n",
            "| Then have those ...|\n",
            "| Gas is too expen...|\n",
            "| Time to come hom...|\n",
            "| You are just afr...|\n",
            "|It‚Äôs actually dis...|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Let's export the positve and negative tweets to text files\n",
        "\n",
        "Some tweets considered positive have sarcastic tone and machine is not abe to detect sarcasm."
      ],
      "metadata": {
        "id": "BB-lrmaRo3U8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "words.select(\"word\").filter(col(\"polarity\") >= 0.5).toPandas().to_csv('positive_tweets')\n",
        "words.select(\"word\").filter(col(\"polarity\") <= -0.5).toPandas().to_csv('negative_tweets')"
      ],
      "metadata": {
        "id": "9c5Kuj-RpAew"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}